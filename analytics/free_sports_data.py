"""
Free Sports Data Sources - Zero-Cost Alternative to Paid APIs
==============================================================

Uses:
1. ESPN Public API (FREE - no API key required)
2. API-Football (FREE - unlimited requests, no credit card)
3. TheSportsDB (FREE - public API, no auth)
4. Statistical models for predictions (no AI API needed)
5. Web scraping with BeautifulSoup (free)

Replaces: SportRadar API, RapidAPI, DeepSeek AI (paid services)
Cost: $0/month - Completely free!
"""

from __future__ import annotations

import logging
import os
from datetime import datetime, timezone

# Python 3.9 compatibility: UTC constant
UTC = timezone.utc
from typing import Any

try:
    import requests
except ImportError:
    requests = None  # type: ignore

try:
    from bs4 import BeautifulSoup
except ImportError:
    BeautifulSoup = None  # type: ignore

# Import world-class prediction functions
try:
    from analytics.world_class_functions import (
        calculate_head_to_head,
        calculate_schedule_strength,
        calculate_travel_impact,
        fetch_market_odds,
        fetch_team_momentum,
    )
except ImportError:
    # Fallback if module not available
    fetch_team_momentum = None
    calculate_head_to_head = None
    calculate_travel_impact = None
    calculate_schedule_strength = None
    fetch_market_odds = None

LOGGER = logging.getLogger(__name__)

# Free API keys (completely free, no credit card needed)
API_FOOTBALL_KEY = os.getenv(
    "API_FOOTBALL_KEY", ""
)  # FREE - sign up at api-football.com (unlimited free tier!)
THE_SPORTS_DB_KEY = os.getenv("THE_SPORTS_DB_KEY", "1")  # Public API key (free, no signup needed)
RAPIDAPI_KEY = os.getenv("RAPIDAPI_KEY", "")  # For injury data (optional, with free fallbacks)

# API endpoints
API_FOOTBALL_BASE = "https://v3.football.api-sports.io"  # Works for all sports, not just football
THE_SPORTS_DB_BASE = "https://www.thesportsdb.com/api/v1/json"

# ESPN Public API (NO API KEY NEEDED!)
ESPN_BASE_URL = "http://site.api.espn.com/apis/site/v2/sports"

ESPN_SPORT_MAPPING = {
    "nfl": "football/nfl",
    "nba": "basketball/nba",
    "mlb": "baseball/mlb",
    "nhl": "hockey/nhl",
    "soccer": "soccer",  # Note: ESPN has limited soccer coverage
}

# Import advanced features
try:
    from analytics.sports_advanced_features import (
        HOME_ADVANTAGE,
        INITIAL_ELO,
        K_FACTOR,
        EloRatingSystem,
        InjuryTracker,
        calculate_home_advantage_score,
        calculate_rest_days,
    )

    ADVANCED_FEATURES_AVAILABLE = True
except ImportError:
    ADVANCED_FEATURES_AVAILABLE = False
    EloRatingSystem = None
    InjuryTracker = None
    calculate_rest_days = None
    calculate_home_advantage_score = None
    K_FACTOR = 32
    HOME_ADVANTAGE = 100
    INITIAL_ELO = 1500


def fetch_team_record_espn(team_name: str, sport: str) -> dict[str, Any] | None:
    """
    Fetch actual team record from ESPN (FREE - no API key needed!).
    Returns wins, losses, and win percentage.
    """
    if not requests:
        return None

    if sport.lower() != "nba":
        return None  # Only NBA for now

    try:
        # ESPN standings endpoint
        url = f"{ESPN_BASE_URL}/basketball/nba/standings"
        response = requests.get(
            url, timeout=15, headers={"User-Agent": "Mozilla/5.0 (compatible; NeoLight/1.0)"}
        )

        if response.status_code != 200:
            return None

        data = response.json()

        # Parse standings - ESPN structure varies, try multiple approaches
        # Method 1: Look in children array (common ESPN structure)
        def find_team_in_children(children, team_search_name):
            if not isinstance(children, list):
                return None
            for item in children:
                if isinstance(item, dict):
                    # Check if this is a team entry
                    team_name_espn = item.get("team", {}).get("displayName", "")
                    if (
                        team_search_name.lower() in team_name_espn.lower()
                        or team_name_espn.lower() in team_search_name.lower()
                    ):
                        stats = item.get("stats", [])
                        for stat in stats:
                            if stat.get("name") == "wins":
                                wins = int(stat.get("value", 0))
                            elif stat.get("name") == "losses":
                                losses = int(stat.get("value", 0))
                        if wins is not None and losses is not None:
                            return {
                                "wins": wins,
                                "losses": losses,
                                "win_pct": wins / (wins + losses) if (wins + losses) > 0 else 0.5,
                            }
                    # Recursively search children
                    if "children" in item:
                        result = find_team_in_children(item["children"], team_search_name)
                        if result:
                            return result
            return None

        # Search in standings structure
        children = data.get("children", [])
        if children:
            result = find_team_in_children(children, team_name)
            if result:
                return result

        # Method 2: Try standings table directly
        standings = data.get("standings", {})
        if isinstance(standings, list):
            for entry in standings:
                team = entry.get("team", {})
                if team_name.lower() in team.get("name", "").lower():
                    wins = int(entry.get("stats", {}).get("wins", 0) or entry.get("wins", 0))
                    losses = int(entry.get("stats", {}).get("losses", 0) or entry.get("losses", 0))
                    if wins + losses > 0:
                        return {"wins": wins, "losses": losses, "win_pct": wins / (wins + losses)}

        return None

    except Exception as e:
        LOGGER.warning(f"Could not fetch ESPN record for {team_name}: {e}")
        return None


def fetch_espn_schedule(sport: str) -> list[dict[str, Any]]:
    """
    Fetch game schedule from ESPN Public API (FREE - no API key!).

    Args:
        sport: Sport name (nfl, nba, mlb, nhl)

    Returns:
        List of game dictionaries with schedule data
    """
    if not requests:
        LOGGER.warning("requests library not available")
        return []

    sport_path = ESPN_SPORT_MAPPING.get(sport.lower())
    if not sport_path:
        LOGGER.warning(f"Unsupported sport for ESPN: {sport}")
        return []

    try:
        # ESPN public endpoint - NO API KEY NEEDED!
        url = f"{ESPN_BASE_URL}/{sport_path}/scoreboard"
        response = requests.get(
            url, timeout=15, headers={"User-Agent": "Mozilla/5.0 (compatible; NeoLight/1.0)"}
        )

        if response.status_code != 200:
            LOGGER.warning(f"ESPN API returned {response.status_code}")
            return []

        data = response.json()
        games = []

        # Parse ESPN response structure
        events = data.get("events", [])
        for event in events:
            try:
                competition = event.get("competitions", [{}])[0]
                competitors = competition.get("competitors", [])

                if len(competitors) < 2:
                    continue

                home_team = None
                away_team = None

                for comp in competitors:
                    if comp.get("homeAway") == "home":
                        home_team = comp.get("team", {}).get("displayName", "Home")
                    elif comp.get("homeAway") == "away":
                        away_team = comp.get("team", {}).get("displayName", "Away")

                if not home_team or not away_team:
                    continue

                game_id = event.get("id", "")
                date = event.get("date", "")

                games.append(
                    {
                        "id": game_id,
                        "game_id": game_id,
                        "home_team": home_team,
                        "away_team": away_team,
                        "scheduled": date,
                        "sport": sport,
                        "status": event.get("status", {})
                        .get("type", {})
                        .get("description", "Scheduled"),
                        "venue": competition.get("venue", {}).get("fullName", ""),
                        "source": "espn",
                    }
                )
            except Exception as e:
                LOGGER.warning(f"Error parsing ESPN event: {e}")
                continue

        LOGGER.info(f"Fetched {len(games)} games from ESPN for {sport}")
        return games

    except Exception as e:
        LOGGER.error(f"Error fetching ESPN schedule: {e}")
        return []


def fetch_team_record_espn(team_name: str, sport: str) -> dict[str, Any] | None:
    """
    Fetch actual team record from ESPN standings (FREE - no API key needed!).
    Returns wins, losses, draws (for soccer), and win percentage.
    Supports: NBA, NFL, Soccer (limited)

    Note: ESPN standings structure may vary, this is a simplified parser.
    """
    if not requests:
        return None

    sport_path = ESPN_SPORT_MAPPING.get(sport.lower())
    if not sport_path or sport.lower() == "soccer":
        # Soccer standings handled differently
        return None

    try:
        # ESPN standings endpoint
        url = f"{ESPN_BASE_URL}/{sport_path}/standings"
        response = requests.get(
            url, timeout=15, headers={"User-Agent": "Mozilla/5.0 (compatible; NeoLight/1.0)"}
        )

        if response.status_code != 200:
            return None

        data = response.json()

        # ESPN standings structure: children -> entries -> team/stats
        def search_standings(obj, team_search_name: str):
            """Recursively search for team in standings structure."""
            if isinstance(obj, dict):
                # Check if this is a team entry
                team = obj.get("team", {})
                team_display = (
                    team.get("displayName", "")
                    or team.get("name", "")
                    or team.get("abbreviation", "")
                )

                if (
                    team_search_name.lower() in team_display.lower()
                    or team_display.lower() in team_search_name.lower()
                ):
                    # Found team, extract stats
                    stats = obj.get("stats", [])
                    wins = None
                    losses = None

                    for stat in stats:
                        stat_name = stat.get("name", "").lower()
                        if stat_name == "wins":
                            wins = int(stat.get("value", 0))
                        elif stat_name == "losses":
                            losses = int(stat.get("value", 0))

                    if wins is not None and losses is not None:
                        return {
                            "wins": wins,
                            "losses": losses,
                            "win_pct": wins / (wins + losses) if (wins + losses) > 0 else 0.5,
                        }

                # Search in children recursively
                for key, value in obj.items():
                    if key == "children" or isinstance(value, (dict, list)):
                        result = search_standings(value, team_search_name)
                        if result:
                            return result

            elif isinstance(obj, list):
                for item in obj:
                    result = search_standings(item, team_search_name)
                    if result:
                        return result

            return None

        result = search_standings(data, team_name)
        return result

    except Exception as e:
        LOGGER.debug(f"Could not fetch ESPN record for {team_name}: {e}")
        return None


def fetch_team_record_from_scoreboard(team_name: str, sport: str) -> dict[str, Any] | None:
    """
    Fetch team record from ESPN scoreboard (FREE - no API key needed!).
    Scoreboard has team records in the competitor data.
    Supports: NBA, NFL, and other ESPN sports.
    """
    if not requests:
        return None

    # Support multiple sports
    sport_path = ESPN_SPORT_MAPPING.get(sport.lower())
    if not sport_path:
        return None

    try:
        url = f"{ESPN_BASE_URL}/{sport_path}/scoreboard"
        response = requests.get(
            url, timeout=15, headers={"User-Agent": "Mozilla/5.0 (compatible; NeoLight/1.0)"}
        )

        if response.status_code != 200:
            return None

        data = response.json()
        events = data.get("events", [])

        # Search through all games for the team
        for event in events:
            competitions = event.get("competitions", [])
            for competition in competitions:
                competitors = competition.get("competitors", [])
                for comp in competitors:
                    team = comp.get("team", {})
                    team_display = team.get("displayName", "") or team.get("name", "")

                    if (
                        team_name.lower() in team_display.lower()
                        or team_display.lower() in team_name.lower()
                    ):
                        # Found team - check records
                        records = comp.get("records", [])
                        for record in records:
                            if isinstance(record, dict):
                                summary = record.get("summary", "")
                                if summary and "-" in summary:
                                    # Parse "W-L" format like "8-5" or "5-9"
                                    try:
                                        parts = summary.split("-")
                                        if len(parts) == 2:
                                            wins = int(parts[0].strip())
                                            losses = int(parts[1].strip())
                                            total = wins + losses
                                            if total > 0:
                                                LOGGER.info(
                                                    f"‚úÖ Found record for {team_name}: {wins}-{losses}"
                                                )
                                                return {
                                                    "wins": wins,
                                                    "losses": losses,
                                                    "win_pct": wins / total,
                                                }
                                    except (ValueError, IndexError):
                                        continue

        return None
    except Exception as e:
        LOGGER.debug(f"Could not fetch record from scoreboard for {team_name}: {e}")
        return None


def scrape_wikipedia_schedule(sport: str, season: str) -> list[dict[str, Any]]:
    """
    Scrape Wikipedia for sports schedules (FREE, reliable structured data).

    Args:
        sport: Sport name
        season: Season year (e.g., "2024")

    Returns:
        List of game dictionaries
    """
    if not requests or not BeautifulSoup:
        return []

    # Wikipedia URLs for different sports
    wikipedia_urls = {
        "nba": f"https://en.wikipedia.org/wiki/{season}‚Äì{int(season)+1}_NBA_season",
        "nfl": f"https://en.wikipedia.org/wiki/{season}_NFL_season",
        "mlb": f"https://en.wikipedia.org/wiki/{season}_Major_League_Baseball_season",
    }

    url = wikipedia_urls.get(sport.lower())
    if not url:
        return []

    try:
        response = requests.get(
            url,
            timeout=15,
            headers={"User-Agent": "Mozilla/5.0 (compatible; NeoLight/1.0; +https://neolight.ai)"},
        )

        if response.status_code != 200:
            return []

        soup = BeautifulSoup(response.content, "html.parser")
        games = []

        # Parse Wikipedia tables (structure varies by sport)
        tables = soup.find_all("table", class_="wikitable")
        for table in tables:
            rows = table.find_all("tr")[1:]  # Skip header
            for row in rows:
                cells = row.find_all(["td", "th"])
                if len(cells) >= 3:
                    try:
                        # Extract team names and date
                        # (This is simplified - would need sport-specific parsing)
                        games.append({"sport": sport, "season": season, "source": "wikipedia"})
                    except Exception:
                        continue

        return games

    except Exception as e:
        LOGGER.warning(f"Error scraping Wikipedia: {e}")
        return []


def fetch_api_football_schedule(sport: str) -> list[dict[str, Any]]:
    """
    Fetch schedule from API-Football (FREE - unlimited requests, no credit card!).

    Args:
        sport: Sport name (nba, nfl, mlb, soccer)

    Returns:
        List of game dictionaries
    """
    if not requests or not API_FOOTBALL_KEY:
        LOGGER.debug("API_FOOTBALL_KEY not set, skipping API-Football")
        return []

    # API-Football uses RapidAPI format
    sport_map = {
        "nba": "basketball",
        "nfl": "americanfootball",
        "mlb": "baseball",
        "soccer": "football",
    }

    api_sport = sport_map.get(sport.lower(), sport.lower())

    try:
        url = f"{API_FOOTBALL_BASE}/fixtures"
        headers = {
            "x-rapidapi-key": API_FOOTBALL_KEY,
            "x-rapidapi-host": "v3.football.api-sports.io",
        }

        # Get today's date
        today = datetime.now(UTC).date().isoformat()

        params = {"date": today}

        # Try sport-specific leagues
        if sport.lower() == "nba":
            params["league"] = "12"  # NBA
        elif sport.lower() == "nfl":
            params["league"] = "1"  # NFL
        elif sport.lower() == "mlb":
            params["league"] = "1"  # MLB

        response = requests.get(url, headers=headers, params=params, timeout=15)

        if response.status_code == 200:
            data = response.json()
            games = []

            for fixture in data.get("response", []):
                try:
                    home = fixture.get("teams", {}).get("home", {}).get("name", "")
                    away = fixture.get("teams", {}).get("away", {}).get("name", "")
                    fixture_id = fixture.get("fixture", {}).get("id", "")
                    scheduled = fixture.get("fixture", {}).get("date", "")

                    if home and away:
                        games.append(
                            {
                                "id": str(fixture_id),
                                "game_id": f"{sport}_{fixture_id}",
                                "home_team": home,
                                "away_team": away,
                                "scheduled": scheduled,
                                "sport": sport,
                                "source": "api-football",
                            }
                        )
                except Exception as e:
                    LOGGER.warning(f"Error parsing API-Football fixture: {e}")
                    continue

            LOGGER.info(f"Fetched {len(games)} games from API-Football for {sport}")
            return games
        else:
            LOGGER.warning(f"API-Football returned {response.status_code}")

    except Exception as e:
        LOGGER.error(f"Error fetching API-Football schedule: {e}")

    return []


def fetch_thesportsdb_schedule(sport: str) -> list[dict[str, Any]]:
    """
    Fetch schedule from TheSportsDB (FREE public API - no auth needed!).

    Args:
        sport: Sport name (nba, nfl, mlb, soccer)

    Returns:
        List of game dictionaries
    """
    if not requests:
        return []

    # TheSportsDB sport/league IDs
    league_map = {
        "nba": "4387",  # NBA
        "nfl": "4391",  # NFL
        "mlb": "4424",  # MLB
        "soccer": "4328",  # Premier League (default)
    }

    league_id = league_map.get(sport.lower(), "4328")

    try:
        # Get today's date
        today = datetime.now(UTC).date()

        # TheSportsDB endpoint
        url = f"{THE_SPORTS_DB_BASE}/{THE_SPORTS_DB_KEY}/eventsday.php"
        params = {
            "d": today.strftime("%Y-%m-%d"),
            "s": "Soccer" if sport.lower() == "soccer" else "Basketball",
        }

        response = requests.get(
            url,
            params=params,
            timeout=15,
            headers={"User-Agent": "Mozilla/5.0 (compatible; NeoLight/1.0)"},
        )

        if response.status_code == 200:
            data = response.json()
            games = []

            events = data.get("events", [])
            for event in events:
                try:
                    home = event.get("strHomeTeam", "")
                    away = event.get("strAwayTeam", "")
                    event_id = event.get("idEvent", "")
                    scheduled = event.get("dateEvent", "")
                    time_event = event.get("strTime", "")

                    if home and away:
                        # Combine date and time
                        if scheduled and time_event:
                            scheduled = f"{scheduled}T{time_event}:00"

                        games.append(
                            {
                                "id": str(event_id),
                                "game_id": f"{sport}_{event_id}",
                                "home_team": home,
                                "away_team": away,
                                "scheduled": scheduled,
                                "sport": sport,
                                "source": "thesportsdb",
                            }
                        )
                except Exception as e:
                    LOGGER.warning(f"Error parsing TheSportsDB event: {e}")
                    continue

            LOGGER.info(f"Fetched {len(games)} games from TheSportsDB for {sport}")
            return games

    except Exception as e:
        LOGGER.error(f"Error fetching TheSportsDB schedule: {e}")

    return []


def fetch_injury_data_espn(sport: str = "nba") -> dict[str, list[str]]:
    """
    Fetch injury data from ESPN (FREE - web scraping).
    Returns dict mapping team names to list of injury reasons.
    Supports: NBA, NFL (soccer has limited injury data on ESPN)

    Also tries RapidAPI if RAPIDAPI_KEY is available (with ESPN fallback).
    """
    if not requests or not BeautifulSoup:
        return {}

    injuries = {}

    # Try RapidAPI first if available (better data)
    if RAPIDAPI_KEY and InjuryTracker:
        try:
            tracker = InjuryTracker(RAPIDAPI_KEY)
            if sport.lower() == "nba":
                rapidapi_injuries = tracker.fetch_nba_injuries()
                if rapidapi_injuries:
                    for inj in rapidapi_injuries:
                        team_info = inj.get("team", {})
                        team_name = team_info.get("name", "")
                        player_info = inj.get("player", {})
                        player_name = player_info.get("name", "")
                        status = inj.get("status", "")
                        reason = inj.get("reason", "")
                        if team_name and player_name:
                            if team_name not in injuries:
                                injuries[team_name] = []
                            injuries[team_name].append(f"{player_name} ({status}): {reason}")
                    LOGGER.info(f"‚úÖ Fetched {len(injuries)} teams with injuries from RapidAPI")
                    return injuries
        except Exception as e:
            LOGGER.debug(f"RapidAPI injury fetch failed: {e}, using ESPN fallback")

    # Fallback to ESPN scraping
    if sport.lower() not in ["nba", "nfl"]:
        return {}  # Only NBA/NFL supported for ESPN scraping

    try:
        url = "https://www.espn.com/nba/injuries"
        response = requests.get(
            url, timeout=15, headers={"User-Agent": "Mozilla/5.0 (compatible; NeoLight/1.0)"}
        )

        if response.status_code != 200:
            return {}

        soup = BeautifulSoup(response.content, "html.parser")
        injuries = {}

        # Parse ESPN injury table
        # ESPN structures injuries by team
        injury_sections = soup.find_all("div", class_="Table__league-injuries")
        for section in injury_sections:
            try:
                # Extract team name
                team_header = section.find("h4", class_="Table__Title")
                if team_header:
                    team_name = team_header.text.strip()
                    # Map ESPN team names to our format (simplified)
                    team_map = {
                        "LA Clippers": "LA Clippers",
                        "Los Angeles Lakers": "Los Angeles Lakers",
                    }
                    team = team_map.get(team_name, team_name)

                    # Extract injuries
                    player_injuries = []
                    rows = section.find_all("tr")
                    for row in rows[1:]:  # Skip header
                        cells = row.find_all("td")
                        if len(cells) >= 3:
                            player = cells[0].text.strip()
                            status = cells[1].text.strip()
                            reason = cells[2].text.strip()
                            if status.lower() in ["out", "doubtful"]:
                                player_injuries.append(f"{player} ({status}): {reason}")

                    if player_injuries:
                        injuries[team] = player_injuries
            except Exception:
                continue

        return injuries
    except Exception as e:
        LOGGER.warning(f"Error fetching ESPN injuries: {e}")
        return {}


def generate_world_class_explanation(
    home_team: str,
    away_team: str,
    home_win_prob: float,
    away_win_prob: float,
    home_elo: float,
    away_elo: float,
    elo_diff: float,
    injuries: dict[str, list[str]] = None,
    home_record: dict[str, Any] = None,
    away_record: dict[str, Any] = None,
    home_rest_days: int = 3,
    away_rest_days: int = 3,
    momentum_data: dict[str, Any] = None,
    h2h_data: dict[str, Any] = None,
    travel_data: dict[str, Any] = None,
) -> list[str]:
    """
    Generate comprehensive world-class explanations including ALL factors.
    """
    explanations = []

    # Real records
    if home_record and away_record:
        home_wins = home_record.get("wins", 0)
        home_losses = home_record.get("losses", 0)
        away_wins = away_record.get("wins", 0)
        away_losses = away_record.get("losses", 0)
        home_win_pct = home_record.get("win_pct", 0.5) * 100
        away_win_pct = away_record.get("win_pct", 0.5) * 100

        explanations.append(
            f"üìä **Current Records:** {home_team} {home_wins}-{home_losses} ({home_win_pct:.1f}%) vs {away_team} {away_wins}-{away_losses} ({away_win_pct:.1f}%)"
        )

        if home_win_pct > away_win_pct:
            explanations.append(
                f"‚úÖ **Record Analysis:** {home_team} has a better record, supporting home advantage."
            )
        elif away_win_pct > home_win_pct:
            explanations.append(
                f"‚ö†Ô∏è **Record Analysis:** {away_team} has a better record, but home advantage makes this closer."
            )
    else:
        explanations.append(
            "‚ö†Ô∏è **WARNING:** Real team records not available - prediction may be inaccurate!"
        )

    # Rest days analysis
    if home_rest_days == 0:
        explanations.append(
            f"‚ö†Ô∏è **Rest Days:** {home_team} is on a back-to-back (0 days rest) - significant fatigue penalty applied."
        )
    elif home_rest_days == 1:
        explanations.append(
            f"‚ö†Ô∏è **Rest Days:** {home_team} has only 1 day rest - fatigue may be a factor."
        )
    elif home_rest_days >= 3:
        explanations.append(
            f"‚úÖ **Rest Days:** {home_team} has {home_rest_days} days rest - well-rested."
        )

    if away_rest_days == 0:
        explanations.append(
            f"‚ö†Ô∏è **Rest Days:** {away_team} is on a back-to-back (0 days rest) - significant fatigue penalty applied."
        )
    elif away_rest_days == 1:
        explanations.append(
            f"‚ö†Ô∏è **Rest Days:** {away_team} has only 1 day rest - fatigue may be a factor."
        )
    elif away_rest_days >= 3:
        explanations.append(
            f"‚úÖ **Rest Days:** {away_team} has {away_rest_days} days rest - well-rested."
        )

    # Travel impact
    if travel_data:
        distance = travel_data.get("travel_distance", 0)
        tz_change = travel_data.get("timezone_change", 0)
        if distance > 1500:
            explanations.append(
                f"‚úàÔ∏è **Travel Impact:** {away_team} traveling {distance:.0f} miles - significant travel fatigue."
            )
        if tz_change >= 3:
            explanations.append(
                f"üïê **Time Zone:** {tz_change}-hour timezone change for {away_team} - additional fatigue penalty."
            )

    # Injuries
    if injuries:
        home_injuries = injuries.get(home_team, [])
        away_injuries = injuries.get(away_team, [])
        if home_injuries:
            explanations.append(
                f"üè• **{home_team} Injuries:** {', '.join(home_injuries[:3])}"
                + ("..." if len(home_injuries) > 3 else "")
            )
        if away_injuries:
            explanations.append(
                f"üè• **{away_team} Injuries:** {', '.join(away_injuries[:3])}"
                + ("..." if len(away_injuries) > 3 else "")
            )

    # Home advantage
    explanations.append(
        "üè† **Home Advantage:** +100 Elo bonus for home team (crowd, familiar venue, no travel)."
    )

    # Elo comparison
    if elo_diff > 150:
        explanations.append(
            f"üìä **Team Strength:** {home_team} significantly stronger ({home_elo:.0f} vs {away_elo:.0f} Elo)."
        )
    elif elo_diff < -150:
        explanations.append(
            f"üìä **Team Strength:** {away_team} significantly stronger ({away_elo:.0f} vs {home_elo:.0f} Elo)."
        )
    else:
        explanations.append(
            f"üìä **Team Strength:** Close matchup ({home_elo:.0f} vs {away_elo:.0f} Elo)."
        )

    # H2H
    if h2h_data and h2h_data.get("h2h_adjustment", 0) != 0:
        h2h_pct = h2h_data.get("h2h_win_pct", 0.5) * 100
        explanations.append(
            f"üìà **Head-to-Head:** {home_team} has won {h2h_data.get('last_10_home_wins', 5)} of last 10 meetings ({h2h_pct:.1f}%)."
        )

    # Momentum
    if momentum_data:
        streak = momentum_data.get("win_streak", 0)
        if streak > 0:
            explanations.append(
                f"üìà **Momentum:** {home_team if streak > 0 else away_team} on {abs(streak)}-game win streak - momentum boost applied."
            )
        elif streak < 0:
            explanations.append(
                f"üìâ **Momentum:** {away_team if streak < 0 else home_team} on {abs(streak)}-game losing streak - momentum penalty applied."
            )

    # Final prediction
    if home_win_prob > 0.65:
        explanations.append(
            f"‚úÖ **Prediction:** {home_team} strong favorite ({home_win_prob*100:.1f}% win probability)."
        )
    elif away_win_prob > 0.65:
        explanations.append(
            f"‚úÖ **Prediction:** {away_team} strong favorite ({away_win_prob*100:.1f}% win probability)."
        )
    else:
        explanations.append(
            f"‚öñÔ∏è **Prediction:** Close game ({home_win_prob*100:.1f}% vs {away_win_prob*100:.1f}%)."
        )

    return explanations


def generate_explanation(
    home_team: str,
    away_team: str,
    home_win_prob: float,
    away_win_prob: float,
    home_elo: float,
    away_elo: float,
    elo_diff: float,
    injuries: dict[str, list[str]] = None,
    home_record: dict[str, Any] = None,
    away_record: dict[str, Any] = None,
) -> list[str]:
    """
    Legacy wrapper for backward compatibility.
    Calls generate_world_class_explanation with default values.
    """
    return generate_world_class_explanation(
        home_team,
        away_team,
        home_win_prob,
        away_win_prob,
        home_elo,
        away_elo,
        elo_diff,
        injuries,
        home_record,
        away_record,
        3,
        3,
        {},
        {},
        {},
    )
    """
    Generate human-readable explanation for the prediction.

    Returns:
        List of explanation strings
    """
    explanations = []

    # Real record information (if available)
    if home_record and away_record:
        home_wins = home_record.get("wins", 0)
        home_losses = home_record.get("losses", 0)
        away_wins = away_record.get("wins", 0)
        away_losses = away_record.get("losses", 0)
        home_win_pct = home_record.get("win_pct", 0.5) * 100
        away_win_pct = away_record.get("win_pct", 0.5) * 100

        explanations.append(
            f"üìä **Current Records:** {home_team} is {home_wins}-{home_losses} ({home_win_pct:.1f}% win rate) vs {away_team} {away_wins}-{away_losses} ({away_win_pct:.1f}% win rate)"
        )

        if home_win_pct > away_win_pct:
            explanations.append(
                f"‚úÖ **Record Analysis:** {home_team} has a better record than {away_team}, which supports the home team advantage prediction."
            )
        elif away_win_pct > home_win_pct:
            explanations.append(
                f"‚ö†Ô∏è **Record Analysis:** {away_team} actually has a better record than {home_team}. However, home advantage (+100 Elo) combined with the close records makes {home_team} the slight favorite."
            )
        else:
            explanations.append(
                "‚öñÔ∏è **Record Analysis:** Both teams have similar records, making this a close matchup where home advantage could be the deciding factor."
            )
    elif home_record:
        home_wins = home_record.get("wins", 0)
        home_losses = home_record.get("losses", 0)
        explanations.append(f"üìä **{home_team} Record:** {home_wins}-{home_losses}")
        explanations.append(
            f"‚ö†Ô∏è **Note:** {away_team} record not available - prediction accuracy reduced."
        )
    elif away_record:
        away_wins = away_record.get("wins", 0)
        away_losses = away_record.get("losses", 0)
        explanations.append(f"üìä **{away_team} Record:** {away_wins}-{away_losses}")
        explanations.append(
            f"‚ö†Ô∏è **Note:** {home_team} record not available - prediction accuracy reduced."
        )
    else:
        explanations.append(
            "‚ö†Ô∏è **WARNING:** Real team records not available. Predictions are based on statistical models only and may not reflect actual team performance. Check current standings before betting!"
        )


def calculate_comprehensive_prediction(game_data: dict[str, Any]) -> dict[str, Any]:
    """
    WORLD-CLASS PREDICTION: Integrates ALL professional betting model factors.

    Factors included:
    1. Real team records & Elo ratings
    2. Team rest & fatigue (back-to-back, travel, time zones)
    3. Injuries & health status (RapidAPI + ESPN fallback)
    4. Momentum & recent form (streaks, point differentials)
    5. Head-to-head matchup history
    6. Schedule strength (opponent quality)
    7. Travel & time zone impact
    8. Home advantage
    9. Market odds (if available)

    Supports: NBA, Soccer, NFL

    Args:
        game_data: Game information dictionary

    Returns:
        Comprehensive prediction dictionary with all factors and explanations
    """
    import hashlib

    sport = game_data.get("sport", "unknown").lower()
    home_team = game_data.get("home_team", "Home")
    away_team = game_data.get("away_team", "Away")
    game_scheduled = game_data.get("scheduled", "")

    # ===== PHASE 1: CORE FACTORS =====

    # 1.1 Fetch real team records (sport-specific)
    home_record = None
    away_record = None

    if sport == "soccer":
        # Soccer: Use API-Football or TheSportsDB
        home_record = fetch_team_record_for_soccer(home_team)
        away_record = fetch_team_record_for_soccer(away_team)
    else:
        # NBA/NFL: Use ESPN scoreboard + standings
        home_record = fetch_team_record_from_scoreboard(home_team, sport)
        if not home_record:
            home_record = fetch_team_record_espn(home_team, sport)

        away_record = fetch_team_record_from_scoreboard(away_team, sport)
        if not away_record:
            away_record = fetch_team_record_espn(away_team, sport)

    # 1.2 Calculate base Elo from real records
    if home_record and away_record:
        home_win_pct = home_record.get("win_pct", 0.5)
        away_win_pct = away_record.get("win_pct", 0.5)
        # Scale: 0.2 win% = 1300 Elo, 0.8 win% = 1700 Elo
        home_base_elo = 1300 + (home_win_pct * 400)
        away_base_elo = 1300 + (away_win_pct * 400)

        # Log records (soccer includes draws)
        home_wins = home_record.get("wins", 0)
        home_losses = home_record.get("losses", 0)
        home_draws = home_record.get("draws", 0)
        away_wins = away_record.get("wins", 0)
        away_losses = away_record.get("losses", 0)
        away_draws = away_record.get("draws", 0)

        if sport == "soccer":
            LOGGER.info(
                f"‚úÖ Using REAL records: {home_team} {home_wins}-{home_draws}-{home_losses}, {away_team} {away_wins}-{away_draws}-{away_losses}"
            )
        else:
            LOGGER.info(
                f"‚úÖ Using REAL records: {home_team} {home_wins}-{home_losses}, {away_team} {away_wins}-{away_losses}"
            )
    else:
        # Fallback: Use hash-based ratings (less accurate)
        LOGGER.warning(
            f"‚ö†Ô∏è Real records not available for {home_team} vs {away_team}, using fallback ratings"
        )
        home_hash = int(hashlib.md5(home_team.encode()).hexdigest()[:8], 16)
        away_hash = int(hashlib.md5(away_team.encode()).hexdigest()[:8], 16)
        home_base_elo = 1500 + (home_hash % 200) - 100
        away_base_elo = 1500 + (away_hash % 200) - 100

    # 1.3 Fetch injuries (RapidAPI first, ESPN fallback)
    injuries = {}
    try:
        injuries = fetch_injury_data_espn(sport)
    except Exception as e:
        LOGGER.debug(f"Could not fetch injuries: {e}")

    # Calculate injury impact on Elo
    home_injury_penalty = 0.0
    away_injury_penalty = 0.0
    if injuries:
        home_injuries = injuries.get(home_team, [])
        away_injuries = injuries.get(away_team, [])
        # Penalty: -50 Elo per "out", -25 per "doubtful"
        for inj in home_injuries:
            if "out" in inj.lower():
                home_injury_penalty -= 50.0
            elif "doubtful" in inj.lower():
                home_injury_penalty -= 25.0
        for inj in away_injuries:
            if "out" in inj.lower():
                away_injury_penalty -= 50.0
            elif "doubtful" in inj.lower():
                away_injury_penalty -= 25.0

    # 1.4 Calculate rest days (back-to-back detection)
    home_rest_days = 3  # Default
    away_rest_days = 3
    home_rest_penalty = 0.0
    away_rest_penalty = 0.0

    # Calculate rest days from recent schedule
    try:
        # Fetch recent games to calculate rest days
        recent_schedule = fetch_espn_schedule(sport)
        if recent_schedule and calculate_rest_days:
            # Filter games for these teams
            home_team_games = [
                g
                for g in recent_schedule
                if (g.get("home_team") == home_team or g.get("away_team") == home_team)
                and g.get("scheduled") < game_scheduled  # Only past games
            ]
            away_team_games = [
                g
                for g in recent_schedule
                if (g.get("home_team") == away_team or g.get("away_team") == away_team)
                and g.get("scheduled") < game_scheduled
            ]

            home_rest_days = calculate_rest_days(home_team_games, home_team, game_scheduled)
            away_rest_days = calculate_rest_days(away_team_games, away_team, game_scheduled)
    except Exception as e:
        LOGGER.debug(f"Could not calculate rest days: {e}")

    # Rest day penalties: Back-to-back = -150, 1 day = -50, 2+ days = 0
    if home_rest_days == 0:
        home_rest_penalty = -150.0
    elif home_rest_days == 1:
        home_rest_penalty = -50.0
    if away_rest_days == 0:
        away_rest_penalty = -150.0
    elif away_rest_days == 1:
        away_rest_penalty = -50.0

    # ===== PHASE 2: ADVANCED FACTORS =====

    # 2.1 Momentum & Recent Form (if historical data available)
    home_momentum_adjustment = 0.0
    away_momentum_adjustment = 0.0
    momentum_data = {}

    if fetch_team_momentum:
        try:
            # Get recent games (would need historical data)
            # For now, use record-based momentum estimate
            if home_record:
                win_pct = home_record["win_pct"]
                if win_pct > 0.6:
                    home_momentum_adjustment = 25.0  # +25 Elo for strong recent form
                elif win_pct < 0.4:
                    home_momentum_adjustment = -25.0  # -25 Elo for weak form

            if away_record:
                win_pct = away_record["win_pct"]
                if win_pct > 0.6:
                    away_momentum_adjustment = 25.0
                elif win_pct < 0.4:
                    away_momentum_adjustment = -25.0
        except Exception as e:
            LOGGER.debug(f"Could not calculate momentum: {e}")

    # 2.2 Head-to-Head Matchup (if historical data available)
    h2h_adjustment = 0.0
    h2h_data = {}
    if calculate_head_to_head:
        try:
            # Would need historical matchup data
            # For now, assume neutral H2H
            h2h_data = {
                "h2h_win_pct": 0.5,
                "last_10_home_wins": 5,
                "h2h_adjustment": 0.0,
            }
        except Exception as e:
            LOGGER.debug(f"Could not calculate H2H: {e}")

    # 2.3 Schedule Strength (if opponent Elo data available)
    sos_home_adjustment = 0.0
    sos_away_adjustment = 0.0
    # Would need opponent Elo ratings - skip for now

    # 2.4 Travel & Time Zone Impact
    travel_adjustment = 0.0
    travel_data = {}
    if calculate_travel_impact:
        try:
            travel_data = calculate_travel_impact(home_team, away_team, game_scheduled)
            travel_adjustment = travel_data.get("travel_penalty", 0.0)
        except Exception as e:
            LOGGER.debug(f"Could not calculate travel: {e}")

    # ===== PHASE 3: MARKET INTELLIGENCE =====

    market_data = {}
    if fetch_market_odds:
        try:
            market_data = fetch_market_odds(game_data.get("game_id", ""), sport) or {}
        except Exception as e:
            LOGGER.debug(f"Could not fetch market odds: {e}")

    # ===== COMBINE ALL FACTORS =====

    # Start with base Elo
    home_elo_final = home_base_elo
    away_elo_final = away_base_elo

    # Apply all adjustments
    home_elo_final += HOME_ADVANTAGE  # Home advantage (+100)
    home_elo_final += home_injury_penalty  # Injury impact
    home_elo_final += home_rest_penalty  # Rest days
    home_elo_final += home_momentum_adjustment  # Momentum

    away_elo_final += away_injury_penalty  # Injury impact
    away_elo_final += away_rest_penalty  # Rest days
    away_elo_final += away_momentum_adjustment  # Momentum
    away_elo_final += travel_adjustment  # Travel penalty

    # H2H adjustment (applied to home team if favorable)
    home_elo_final += h2h_data.get("h2h_adjustment", 0.0)

    # Calculate final win probabilities
    elo_diff = home_elo_final - away_elo_final
    home_win_prob = 1 / (1 + 10 ** (-elo_diff / 400))
    away_win_prob = 1 - home_win_prob

    # Normalize
    total = home_win_prob + away_win_prob
    if total > 0:
        home_win_prob = home_win_prob / total
        away_win_prob = away_win_prob / total

    # Confidence based on Elo difference
    confidence = min(abs(elo_diff) / 300, 0.9)
    if confidence < 0.5:
        confidence = 0.55

    # Edge calculation
    edge = max(abs(home_win_prob - 0.5) * 0.2, 0.02)

    recommended_side = home_team if home_win_prob > away_win_prob else away_team

    # ===== GENERATE COMPREHENSIVE EXPLANATIONS =====
    explanations = generate_world_class_explanation(
        home_team,
        away_team,
        home_win_prob,
        away_win_prob,
        home_elo_final,
        away_elo_final,
        elo_diff,
        injuries,
        home_record,
        away_record,
        home_rest_days,
        away_rest_days,
        momentum_data,
        h2h_data,
        travel_data,
    )

    return {
        "game_id": game_data.get("game_id", ""),
        "home_team": home_team,
        "away_team": away_team,
        "home_win_probability": round(home_win_prob, 3),
        "away_win_probability": round(away_win_prob, 3),
        "confidence": round(confidence, 3),
        "edge": round(edge, 3),
        "recommended_side": recommended_side,
        "sport": sport,
        "scheduled": game_scheduled,
        "model": "world-class-ensemble",
        "source": "free_sources_rapidapi",
        "elo_home": round(home_elo_final, 1),
        "elo_away": round(away_elo_final, 1),
        "elo_base_home": round(home_base_elo, 1),
        "elo_base_away": round(away_base_elo, 1),
        "adjustments": {
            "home_injury": round(home_injury_penalty, 1),
            "away_injury": round(away_injury_penalty, 1),
            "home_rest": round(home_rest_penalty, 1),
            "away_rest": round(away_rest_penalty, 1),
            "home_momentum": round(home_momentum_adjustment, 1),
            "away_momentum": round(away_momentum_adjustment, 1),
            "travel": round(travel_adjustment, 1),
            "h2h": round(h2h_data.get("h2h_adjustment", 0.0), 1),
        },
        "explanations": explanations,
        "injury_info": {
            "home_injuries": injuries.get(home_team, []),
            "away_injuries": injuries.get(away_team, []),
        }
        if injuries
        else {},
        "records": {"home": home_record, "away": away_record}
        if (home_record or away_record)
        else {},
        "factors_used": {
            "real_records": bool(home_record and away_record),
            "injuries": bool(injuries),
            "rest_days": True,
            "momentum": bool(momentum_data),
            "head_to_head": bool(h2h_data),
            "travel": bool(travel_data),
            "market_odds": bool(market_data),
        },
    }


def generate_statistical_prediction(game_data: dict[str, Any]) -> dict[str, Any]:
    """
    Generate prediction using world-class comprehensive model.
    Wrapper function that calls calculate_comprehensive_prediction().
    Maintained for backward compatibility.
    """
    try:
        return calculate_comprehensive_prediction(game_data)
    except Exception as e:
        LOGGER.warning(f"Comprehensive prediction failed: {e}, using fallback")
        return fallback_prediction(game_data)


def fallback_prediction(game_data: dict[str, Any]) -> dict[str, Any]:
    """
    Fallback prediction using simple statistical model (FREE).

    Args:
        game_data: Game information

    Returns:
        Basic prediction with 55/45 split favoring home team
    """
    return {
        "game_id": game_data.get("game_id", ""),
        "home_team": game_data.get("home_team", "Home"),
        "away_team": game_data.get("away_team", "Away"),
        "home_win_probability": 0.55,  # Home advantage
        "away_win_probability": 0.45,
        "confidence": 0.50,  # Low confidence for fallback
        "edge": 0.0,
        "recommended_side": game_data.get("home_team", "Home"),
        "sport": game_data.get("sport", "unknown"),
        "scheduled": game_data.get("scheduled", ""),
        "model": "fallback-statistical",
        "source": "fallback",
    }


def get_free_sports_schedule(sport: str) -> list[dict[str, Any]]:
    """
    Get sports schedule using free sources with statistical predictions.

    Multi-tier fallback:
    1. ESPN Public API (free, no key)
    2. API-Football (free, unlimited)
    3. TheSportsDB (free public API)
    4. Statistical predictions (no API needed!)

    Args:
        sport: Sport name (nfl, nba, mlb, nhl, soccer)

    Returns:
        List of games with predictions
    """
    games = []

    # Tier 1: Try ESPN Public API first (no key needed!)
    espn_games = fetch_espn_schedule(sport)
    if espn_games:
        LOGGER.info(f"‚úÖ Found {len(espn_games)} games from ESPN for {sport}")
        games.extend(espn_games)

    # Tier 2: Try API-Football (free, unlimited if API key set)
    if not games and API_FOOTBALL_KEY:
        api_football_games = fetch_api_football_schedule(sport)
        if api_football_games:
            LOGGER.info(f"‚úÖ Found {len(api_football_games)} games from API-Football for {sport}")
            games.extend(api_football_games)

    # Tier 3: Try TheSportsDB (free public API, no key needed!)
    if not games:
        thesportsdb_games = fetch_thesportsdb_schedule(sport)
        if thesportsdb_games:
            LOGGER.info(f"‚úÖ Found {len(thesportsdb_games)} games from TheSportsDB for {sport}")
            games.extend(thesportsdb_games)

    if not games:
        LOGGER.warning(f"No games found from any free source for {sport}")
        return []

    # Remove duplicates (by game_id)
    seen_ids = set()
    unique_games = []
    for game in games:
        game_id = game.get("game_id", "")
        if game_id and game_id not in seen_ids:
            seen_ids.add(game_id)
            unique_games.append(game)

    # Generate statistical predictions for all games
    predictions = []
    for game in unique_games:
        try:
            prediction = generate_statistical_prediction(game)
            predictions.append(prediction)
        except Exception as e:
            LOGGER.warning(f"Prediction failed for game {game.get('id')}: {e}")
            predictions.append(fallback_prediction(game))

    LOGGER.info(f"Generated {len(predictions)} predictions for {sport}")
    return predictions


__all__ = [
    "fetch_espn_schedule",
    "fetch_api_football_schedule",
    "fetch_thesportsdb_schedule",
    "generate_statistical_prediction",
    "calculate_comprehensive_prediction",
    "get_free_sports_schedule",
    "fallback_prediction",
    "fetch_team_record_for_soccer",
]
